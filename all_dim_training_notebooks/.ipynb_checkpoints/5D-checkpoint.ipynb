{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733591e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97735/3888904027.py:10: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from IPython.core.display import display\n",
    "from collections.abc import Mapping\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import torchmetrics\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad13d3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR2 or DR3: DR2\n",
      "Input how many dimensions are needed: 5D\n",
      "Use m12i or m12f data: m12i\n",
      "Transfer learning (True or False): True\n",
      "Which galaxy parameters for transfer learning: m12f\n"
     ]
    }
   ],
   "source": [
    "#User Input\n",
    "sim = input(\"DR2 or DR3: \")\n",
    "dim = input(\"Input how many dimensions are needed: \")\n",
    "galaxy = input(\"Use m12i or m12f data: \")\n",
    "transfer = bool(input(\"Transfer learning (True or False): \"))\n",
    "if transfer == True:\n",
    "    transfer_galaxy = input(\"Which galaxy parameters for transfer learning: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796ffd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "if dim == '4D':\n",
    "    x_keys = ['ra', 'dec', 'pmra', 'pmdec']\n",
    "elif dim == '5D':\n",
    "    x_keys = ['ra', 'dec', 'pmra', 'pmdec', 'parallax']\n",
    "elif dim == '6D':\n",
    "    x_keys = ['ra', 'dec', 'pmra', 'pmdec', 'parallax', 'radial_velocity']\n",
    "elif dim == '7D':\n",
    "    x_keys = ['ra', 'dec', 'pmra', 'pmdec', 'parallax', 'radial_velocity', 'feh']\n",
    "elif dim == '9D':\n",
    "    x_keys = ['ra', 'dec', 'pmra', 'pmdec', 'parallax', 'radial_velocity', 'Jr', 'Jphi', 'Jz']\n",
    "elif dim == '10D':\n",
    "    x_keys = ['ra', 'dec', 'pmra', 'pmdec', 'parallax', 'radial_velocity', 'Jr', 'Jphi', 'Jz', 'feh']\n",
    "    \n",
    "y_key = 'is_accreted'\n",
    "\n",
    "# Directories\n",
    "path = '/ocean/projects/phy210068p/hsu1/Ananke_datasets_training/Ananke'+ sim + '_data_reduced_' + galaxy + '.hdf5'\n",
    "out_dir = '/ocean/projects/phy210068p/hsu1/Training_results/' + sim + '/' + galaxy + '/' + dim\n",
    "roc_title = sim + '_' + galaxy + '_' + dim\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 1024\n",
    "roc_path = '/ocean/projects/phy210068p/hsu1/Training_results/' + sim + '/' + galaxy + 'roc_parameters.hdf5'\n",
    "\n",
    "if transfer == True:\n",
    "    out_dir = out_dir + '_transfer'\n",
    "    transfer_checkpoint = '/ocean/projects/phy210068p/hsu1/Training_results/' + sim +'/'+ transfer_galaxy +'/'+ dim + '/training_logs/version_0/checkpoints/last.ckpt'\n",
    "    roc_title = sim + '_' + transfer_galaxy + '_on_' + galaxy\n",
    "    roc_path = '/ocean/projects/phy210068p/hsu1/Training_results/' + sim + '/' + roc_title + '_roc_parameters.hdf5'\n",
    "\n",
    "train_parameter_file = out_dir + '/training_parameters.hdf5'\n",
    "train_log = out_dir + '/training_logs'\n",
    "checkpoint = train_log + '/version_0/checkpoints/last.ckpt'\n",
    "    \n",
    "#Saving roc curves\n",
    "def save_roc(roc_path, epsilon_i, epsilon_a):\n",
    "    with h5py.File(roc_path, 'a') as f:\n",
    "        if dim + '_ep_i' in f.keys():\n",
    "            del f[dim + '_ep_i']\n",
    "            del f[dim + '_ep_a']\n",
    "            f.create_dataset(dim + '_ep_i', data=epsilon_i)\n",
    "            f.create_dataset(dim + '_ep_a', data=epsilon_a)\n",
    "        else:\n",
    "            f.create_dataset(dim + '_ep_i', data=epsilon_i)\n",
    "            f.create_dataset(dim + '_ep_a', data=epsilon_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5bb23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "f = h5py.File(path, 'r')\n",
    "\n",
    "for i in x_keys:\n",
    "    data.append(f[i][:])\n",
    "y = f[y_key][:]\n",
    "\n",
    "# Getting rid of nan values\n",
    "x = []\n",
    "if 'Jr' in x_keys:\n",
    "    Jr = f['Jr'][:]\n",
    "    mask = (~np.isnan(Jr))\n",
    "    for i in range(len(x_keys)):\n",
    "        new = data[i][:][mask]\n",
    "        x.append(new)\n",
    "    y = y[mask]\n",
    "elif 'radial_velocity' in x_keys:\n",
    "    rv = f['radial_velocity'][:]\n",
    "    mask = (~np.isnan(rv))\n",
    "    for i in range(len(x_keys)):\n",
    "        new = data[i][:][mask]\n",
    "        x.append(new)\n",
    "    y = y[mask]\n",
    "else:\n",
    "    x = data\n",
    "\n",
    "x = np.vstack(x).T\n",
    "f.close()\n",
    "\n",
    "shuffle = np.random.permutation(len(x))\n",
    "x = x[shuffle]\n",
    "y = y[shuffle]\n",
    "\n",
    "n_train = int(0.9 *len(x))\n",
    "n_val = len(x)-n_train\n",
    "train_x, val_x = x[:n_train], x[n_train: n_train+n_val]\n",
    "train_y, val_y = y[:n_train], y[n_train: n_train+n_val]\n",
    "\n",
    "ny1 = np.sum(train_y==1)\n",
    "ny0 = np.sum(train_y==0)\n",
    "ny = ny1 + ny0\n",
    "w1 = ny/ny1\n",
    "w0 = ny/ny0\n",
    "weight = torch.tensor([w0, w1], dtype=torch.float32)\n",
    "mean_train_x = np.mean(train_x, axis = 0)\n",
    "stdv_train_x = np.std(train_x, axis = 0)\n",
    "train_x = (train_x - mean_train_x) / stdv_train_x\n",
    "val_x = (val_x - mean_train_x) / stdv_train_x\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.long)\n",
    "val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "val_dataset = TensorDataset(val_x, val_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size)\n",
    "\n",
    "with h5py.File(train_parameter_file, 'w') as f:\n",
    "    f.create_dataset('shuffle', data=shuffle)\n",
    "    f.attrs['n_train']=n_train\n",
    "    f.attrs['n_val']=n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c239e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(LightningModule):\n",
    "                \n",
    "    def __init__(self, weight, mean_train_x, stdv_train_x, transfer):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.l1 = torch.nn.Linear(len(x_keys), 100) \n",
    "        self.l2 = torch.nn.Linear(100, 50)\n",
    "        self.l3 = torch.nn.Linear(50, 2)\n",
    "        \n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "        self.weight = weight\n",
    "        self.mean_train_x = mean_train_x\n",
    "        self.stdv_train_x = stdv_train_x\n",
    "        if transfer == True:\n",
    "            self.feature_extractor = Model.load_from_checkpoint(transfer_checkpoint, transfer=False)\n",
    "            self.feature_extractor.freeze()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_out = self.l1(x)\n",
    "        x_out = torch.relu(x_out)\n",
    "        x_out = self.l2(x_out)\n",
    "        x_out = torch.relu(x_out)\n",
    "        x_out = self.l3(x_out)\n",
    "        return x_out\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        train_x, train_y = batch \n",
    "        preds = self(train_x)\n",
    "        loss = F.cross_entropy(preds, train_y, weight = self.weight.to(self.device))\n",
    "        self.train_acc(preds, train_y)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        val_x, val_y = batch\n",
    "        preds = self(val_x)\n",
    "        loss = F.cross_entropy(preds, val_y, weight=self.weight.to(self.device))\n",
    "        self.valid_acc(preds, val_y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('valid_acc', self.valid_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e4fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /ocean/projects/phy210068p/hsu1/Training_results/DR2/m12i/5D_transfer/training_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type     | Params\n",
      "-----------------------------------------------\n",
      "0 | l1                | Linear   | 600   \n",
      "1 | l2                | Linear   | 5.0 K \n",
      "2 | l3                | Linear   | 102   \n",
      "3 | train_acc         | Accuracy | 0     \n",
      "4 | valid_acc         | Accuracy | 0     \n",
      "5 | feature_extractor | Model    | 5.8 K \n",
      "-----------------------------------------------\n",
      "5.8 K     Trainable params\n",
      "5.8 K     Non-trainable params\n",
      "11.5 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/hsu1/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/jet/home/hsu1/anaconda3/envs/torch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92531f6ca070459b8dbc859a503c27a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if transfer == True:\n",
    "    model = Model(weight, mean_train_x, stdv_train_x, transfer=True)\n",
    "else:\n",
    "    model = Model(weight, mean_train_x, stdv_train_x, transfer=False)\n",
    "\n",
    "# Create trainer\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"val_loss\", mode='min', filename=\"{epoch}-{val_loss:.4f}\",\n",
    "        save_top_k=3, save_last=True, save_weights_only=True),\n",
    "    EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=5, mode='min', verbose=True)\n",
    "]\n",
    "trainer_logger = CSVLogger(out_dir, name=train_log)\n",
    "trainer = Trainer(\n",
    "    accelerator=\"auto\", devices=1 if torch.cuda.is_available() else None,\n",
    "    max_epochs=10, default_root_dir=out_dir,\n",
    "    callbacks=callbacks, logger=trainer_logger, enable_progress_bar=True )\n",
    "\n",
    "# Start training\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load_from_checkpoint(checkpoint)\n",
    "mean = model.mean_train_x\n",
    "stdv = model.stdv_train_x\n",
    "weight = model.weight\n",
    "\n",
    "n_test = n_val\n",
    "test_x = x[n_train: n_train+n_test]\n",
    "test_y = y[n_train: n_train+n_test]\n",
    "\n",
    "test_x = (test_x - mean) / stdv\n",
    "\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.long)\n",
    "\n",
    "test_dataset = list(zip(test_x, test_y))\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size)\n",
    "\n",
    "predict = []\n",
    "target = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x, y = batch\n",
    "        yhat = model(x)\n",
    "        predict.append(yhat.cpu().numpy())\n",
    "        target.append(y.cpu().numpy())\n",
    "predict = np.concatenate(predict)\n",
    "target = np.concatenate(target)\n",
    "\n",
    "score = np.exp(predict[:,1])/(np.exp(predict[:,0])+np.exp(predict[:,1]))\n",
    "target_true_mask = (target==True)\n",
    "target_false_mask = (target==False)\n",
    "\n",
    "thresholds = np.linspace(0.001, 1, 100)\n",
    "precision = []\n",
    "recall = []\n",
    "epsilon_a = []\n",
    "epsilon_i = []\n",
    "for thres in thresholds:\n",
    "    score_1 = score>thres\n",
    "    score_1_true_mask = (score_1==True)\n",
    "    score_1_false_mask = (score_1==False)\n",
    "    TP = np.sum(score_1[target_true_mask])\n",
    "    FP = np.sum(score_1[target_false_mask])\n",
    "    TN = np.sum(~score_1[target_false_mask])\n",
    "    FN = np.sum(~score_1[target_true_mask])\n",
    "    N_a = TP + FN\n",
    "    N_i = TN + FP\n",
    "    N_a_s = TP\n",
    "    N_i_s = FP\n",
    "    epsilon_a_thres = N_a_s / N_a\n",
    "    epsilon_i_thres = N_i_s / N_i\n",
    "    epsilon_a.append(epsilon_a_thres)\n",
    "    epsilon_i.append(epsilon_i_thres)\n",
    "\n",
    "save_roc(roc_path, epsilon_i, epsilon_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "ax.plot(epsilon_i, epsilon_a, linewidth=6)\n",
    "ax.plot(0.045, 0.86, markersize=10, marker='D', label='V Selection')\n",
    "ax.plot(0.011, 0.862, markersize=10, marker='s', label='VM Selection')\n",
    "#ax.plot(0.3, 0.1, markersize=20, marker=(5, 1))\n",
    "ax.set_title(roc_title, fontsize=40)\n",
    "ax.set_xlabel(r'$\\epsilon_I$', fontsize=35)\n",
    "ax.set_ylabel(r'$\\epsilon_A$', fontsize=35)\n",
    "ax.set_xscale('log')\n",
    "ax.tick_params(axis='both', labelsize=35)\n",
    "ax.legend(fontsize=15, loc='lower right')\n",
    "plt.xlim([0.001,1])\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967e024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
